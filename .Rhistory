table(crime)
# number of rows in the Boston dataset
n <- nrow(boston_scaled)
n
# choose randomly 80% of the rows
ind <- sample(n,  size = n * 0.8)
length(ind)
# create train set
train <- boston_scaled[ind,]
dim(train)
# create test set
test <- boston_scaled[-ind,]
dim(test)
# save the correct classes from test data
correct_classes <- test$crime
summary(train$crim)
# remove the crime variable from test data
test <- dplyr::select(test, -crime)
colnames(train$crim)
library(dplyr)
library(MASS)
library(corrplot)
library(tidyverse)
# save the scaled crim as scaled_crim
scaled_crim <- scale(boston_scaled$crim)
# summary of the scaled_crim
summary(scaled_crim)
dim(scaled_crim)
# create a quantile vector of crim and print it
bins <- quantile(scaled_crim)
bins
# create a categorical variable 'crime'
crime <- cut(scaled_crim, breaks = bins, include.lowest = TRUE, labels(c("low", "med-low", "med-high", "high")))
# look at the table of the new factor crime
table(crime)
# number of rows in the Boston dataset
n <- nrow(boston_scaled)
n
# choose randomly 80% of the rows
ind <- sample(n,  size = n * 0.8)
length(ind)
# create train set
train <- boston_scaled[ind,]
dim(train)
# create test set
test <- boston_scaled[-ind,]
dim(test)
# save the correct classes from test data
correct_classes <- test$crime
crime <-as.numeric(as.character(crime))
summary(train$crim)
# remove the crime variable from test data
test <- dplyr::select(test, -crime)
summary(crime)
?dplyr::select
train <-as.character(numeric(train))
summary(train)
train$medv <-as.character(numeric(train$medv))
train$medv <-as.numeric(as.character(train$medv))
train <-as.numeric(as.character(train))
summary(train)
library(MASS)
# linear discriminant analysis
lda.fit <- lda(crime ~ . , data = train)
train <- boston_scaled[ind,]
dim(train)
train$. <- as.numeric(as.character(train$.))
train$medv <- as.numeric(as.character(train$medv))
summary(train)
train$medv <- as.numeric(as.character(train$medv))
train$crim <- as.numeric(as.character(train$crim))
train$zn <- as.numeric(as.character(train$zn))
train$indus <- as.numeric(as.character(train$indus))
train$chas <- as.numeric(as.character(train$chas))
train$nox <- as.numeric(as.character(train$nox))
train$rm <- as.numeric(as.character(train$rm))
train$age <- as.numeric(as.character(train$age))
train$dis <- as.numeric(as.character(train$dis))
train$rad <- as.numeric(as.character(train$rad))
train$tax <- as.numeric(as.character(train$tax))
train$ptratio <- as.numeric(as.character(train$ptratio))
train$black <- as.numeric(as.character(train$black))
train$lstat <- as.numeric(as.character(train$lstat))
str(train)
lda.fit <- lda(crime ~ . , data = train)
?lda()
lda.fit <- lda(crime ~ . , data = train, na.action = na.exclude)
library(dplyr)
library(MASS)
library(corrplot)
library(tidyverse)
# boston_scaled is available
summary(Boston)
# save the scaled crim as scaled_crim
scaled_crim <- scale(boston_scaled$crim)
# summary of the scaled_crim
summary(scaled_crim)
# create a quantile vector of crim and print it
bins <- quantile(scaled_crim)
bins
# create a categorical variable 'crime'
crime <- cut(scaled_crim, breaks = bins, include.lowest = TRUE, labels(c("low", "med-low", "med-high", "high")))
# look at the table of the new factor crime
table(crime)
# remove original crim from the dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)
# add the new categorical value to scaled data
boston_scaled <- data.frame(boston_scaled, crime)
# number of rows in the Boston dataset
n <- nrow(boston_scaled)
n
# choose randomly 80% of the rows
ind <- sample(n,  size = n * 0.8)
length(ind)
# create train set
train <- boston_scaled[ind,]
dim(train)
# create test set
test <- boston_scaled[-ind,]
dim(test)
# save the correct classes from test data
correct_classes <- test$crime
crime <-as.numeric(as.character(crime))
summary(train$crim)
# remove the crime variable from test data
test <- dplyr::select(test, -crime)
summary(crime)
?dplyr::select
library(MASS)
# linear discriminant analysis
lda.fit <- lda(crime ~ . , data = train, na.action = na.exclude)
?lda()
length(train$crim)
length(crime)
length(train$nox)
# print the lda.fit object
lda.fit
plot(lda.fit, dimen = 3, col = classes, pch= classes)
library(MASS)
# linear discriminant analysis
lda.fit <- lda(crime ~ . , data = train, na.action = na.exclude)
?lda()
length(train$crim)
length(crime)
length(train$nox)
# print the lda.fit object
lda.fit
# target classes as numeric
classes <- as.numeric(train$crime)
plot(lda.fit, dimen = 3, col = classes, pch= classes)
# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# plot the lda results
plot(lda.fit, dimen = 2, col  =classes, pch =classes)
lda.arrows(lda.fit, myscale = 10)
library(MASS)
# linear discriminant analysis
lda.fit <- lda(crime ~ . , data = train, na.action = na.exclude)
?lda()
length(train$crim)
length(crime)
length(train$nox)
# print the lda.fit object
lda.fit
# target classes as numeric
classes <- as.numeric(train$crime)
plot(lda.fit, dimen = 3, col = classes, pch= classes)
# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# plot the lda results
plot(lda.fit, dimen = 2, col  =classes, pch =classes)
lda.arrows(lda.fit, myscale = 6)
library(MASS)
# linear discriminant analysis
lda.fit <- lda(crime ~ . , data = train, na.action = na.exclude)
?lda()
length(train$crim)
length(crime)
length(train$nox)
# print the lda.fit object
lda.fit
# target classes as numeric
classes <- as.numeric(train$crime)
plot(lda.fit, dimen = 3, col = classes, pch= classes)
# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# plot the lda results
plot(lda.fit, dimen = 2, col  =classes, pch =classes)
lda.arrows(lda.fit, myscale = 3)
library(MASS)
# linear discriminant analysis
lda.fit <- lda(crime ~ . , data = train, na.action = na.exclude)
?lda()
length(train$crim)
length(crime)
length(train$nox)
# print the lda.fit object
lda.fit
# target classes as numeric
classes <- as.numeric(train$crime)
plot(lda.fit, dimen = 3, col = classes, pch= classes)
# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# plot the lda results
plot(lda.fit, dimen = 2, col  =classes, pch =classes)
lda.arrows(lda.fit, myscale = 10)
# lda.fit, correct_classes and test are available
?predict.lda
# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)
# cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)
data("Boston")
?scale()
install.packages("clusterSim")
library(clusterSim)
data.Normalization (Boston,type="n2",normalization="column")
data.Normalization (x,type="n2",normalization="row")
data.Normalization (Boston,type="n2",normalization="row")
data("Boston")
library(clusterSim)
?scale
data.Normalization (Boston,type="n2",normalization="row")
library(MASS)
dist_eu <- dist(Boston)
summary(dist_eu)
km <-kmeans(dist_eu, centers = 4)
pairs(Boston, col = km$cluster)
library(ggplot2)
set.seed(123)
k_max <- 10
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
# visualize the results
plot(1:k_max, twcss, type='b')
km <-kmeans(dist_eu, centers = 2)
pairs(Boston, col = km$cluster)
km <-kmeans(dist_eu, centers = 3)
lda.fit <- lda(km$cluster ~ . , data = Boston)
lda.fit
classes <- as.numeric(Boston$km$cluster)
classes <- as.numeric(km$cluster)
plot(lda.fit, dimen = 3, col = classes, pch= classes)
# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# plot the lda results
plot(lda.fit, dimen = 2, col  =classes, pch =classes)
lda.arrows(lda.fit, myscale = 10)
lda.arrows(lda.fit, myscale = 20)
plot(lda.fit, dimen = 3, col = classes, pch= classes)
# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# plot the lda results
plot(lda.fit, dimen = 2, col  =classes, pch =classes)
lda.arrows(lda.fit, myscale = 20)
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
glimpse(hd)
str(hd)
summary(hd)
glimpse(gii)
str(gii)
summary(gii)
colnames(hd)
hd[1] <- "HDI index"
colnames(hd)
colnames(hd)[1] <- "Human Development Index"
data("Boston")
library(clusterSim)
data.Normalization (Boston,type="n3a",normalization="row")
?data.Normalization
library(MASS)
# euclidean distance matrix
dist_eu <- dist(Boston)
# k-means clustering
km <-kmeans(dist_eu, centers = 4)
km <-kmeans(dist_eu, centers = 6)
km <-kmeans(dist_eu, centers = 10)
km <-kmeans(dist_eu, centers = 15)
# plot the Boston dataset with clusters
pairs(Boston, col = km$cluster)
library(ggplot2)
# MASS, ggplot2 and Boston dataset are available
set.seed(123)
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
# visualize the results
plot(1:k_max, twcss, type='b')
# k-means clustering
km <-kmeans(dist_eu, centers = 1)
# plot the Boston dataset with clusters
pairs(Boston, col = km$cluster)
# k-means clustering
km <-kmeans(dist_eu, centers = 3)
data("Boston")
library(clusterSim)
data.Normalization (Boston,type="n1",normalization="row")
?data.Normalization
library(MASS)
# euclidean distance matrix
dist_eu <- dist(Boston)
# k-means clustering
km <-kmeans(dist_eu, centers = 4)
km <-kmeans(dist_eu, centers = 6)
km <-kmeans(dist_eu, centers = 10)
km <-kmeans(dist_eu, centers = 15)
# plot the Boston dataset with clusters
pairs(Boston, col = km$cluster)
library(ggplot2)
# MASS, ggplot2 and Boston dataset are available
set.seed(123)
# determine the number of clusters
k_max <- 10
data("Boston")
library(clusterSim)
data.Normalization (Boston,type="n1",normalization="column")
?data.Normalization
library(MASS)
# euclidean distance matrix
dist_eu <- dist(Boston)
# k-means clustering
km <-kmeans(dist_eu, centers = 4)
km <-kmeans(dist_eu, centers = 6)
km <-kmeans(dist_eu, centers = 10)
km <-kmeans(dist_eu, centers = 15)
# plot the Boston dataset with clusters
pairs(Boston, col = km$cluster)
library(ggplot2)
# MASS, ggplot2 and Boston dataset are available
set.seed(123)
# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
# visualize the results
plot(1:k_max, twcss, type='b')
# k-means clustering
km <-kmeans(dist_eu, centers = 1)
# plot the Boston dataset with clusters
pairs(Boston, col = km$cluster)
# k-means clustering
km <-kmeans(dist_eu, centers = 3)
colnames(hd)
colnames(gii)
colnames(hd)
colnames(hd)[1] <- "Human Development Index Rank"
colnames(hd)[2] <- "Country"
colnames(hd)[3] <- "Human Development Index"
colnames(hd)[4] <- "Life Expectancy"
colnames(hd)[5] <- "Years of education (expected)"
colnames(hd)[6] <- "Years of education (mean)"
colnames(hd)[7] <- "GNI per capita"
colnames(hd)[8] <- "GNI per capita - HDI Rank"
colnames(hd)
colnames(gii)[1] <- "Gender Inequality Index Rank"
colnames(gii)[2] <- "Country"
colnames(gii)[3] <- "Gender Inequality Index"
colnames(gii)[4] <- "Maternal mortality"
colnames(gii)[5] <- "Adolescent Birth"
colnames(gii)[6] <- "Representation in Parliament"
colnames(gii)[7] <- "Women'secondary education"
colnames(gii)[8] <- "Men's Secondary education"
colnames(gii)[9] <- "Women's Labour Force participation"
colnames(gii)[10] <- "Men's Labour Force participation"
colnames(hd)
colnames(gii)
gii <- mutate(gii, eduRatioFM = edu2F / edu2M)
library(gmodels)
library(gdata)
library(dplyr) #accessed the dplyr-library
library(ggplot2) #accessed the ggplot2-library
library(readr) #accessed the readr-library
library(tidyr) #accessed tidyr-library
gii <- mutate(gii, eduRatioFM = edu2F / edu2M)
gii <- mutate(gii, eduRatioFM = edu2F/edu2M)
summary(hd)
colnames(hd)[1] <- "HDIR"
colnames(hd)[2] <- "Country"
colnames(hd)[3] <- "HDI"
colnames(hd)[4] <- "LifeExp"
colnames(hd)[5] <- "YrsEduExp"
colnames(hd)[6] <- "YrsEduMean"
colnames(hd)[7] <- "GNIpercapita"
colnames(hd)[8] <- "GNIpercapita-HDIR"
colnames(gii)
colnames(gii)[1] <- "GIIR"
colnames(gii)[2] <- "Country"
colnames(gii)[3] <- "GII"
colnames(gii)[4] <- "MaternalMort"
colnames(gii)[5] <- "AdolBirth"
colnames(gii)[6] <- "ReprParliament"
colnames(gii)[7] <- "edu2F"
colnames(gii)[8] <- "edu2M"
colnames(gii)[9] <- "LabForF"
colnames(gii)[10] <- "LabForM"
gii <- mutate(gii, eduRatioFM = edu2F/edu2M)
gii <- mutate(gii, labRatioFM = labF / labM)
colnames(gii)
colnames(gii)[1] <- "GIIR"
colnames(gii)[2] <- "Country"
colnames(gii)[3] <- "GII"
colnames(gii)[4] <- "MaternalMort"
colnames(gii)[5] <- "AdolBirth"
colnames(gii)[6] <- "RepParliament"
colnames(gii)[7] <- "edu2F"
colnames(gii)[8] <- "edu2M"
colnames(gii)[9] <- "labF"
colnames(gii)[10] <- "labM"
gii <- mutate(gii, labRatioFM = labF / labM)
library(dplyr)
summary(Country)
summary("Country")
str("Country")
hd$Country
?inner_join
join_by <- c("hd$Country", "gii$Country")
join_by
gii$Country
male_students <- filter(hd, hd$Country == gii$Country)
common_by(by = Country, hd, gii)
Country <- hd$Country + gii$Country
Country <- c(hd$Country + gii$Country)
Country <- c(hd$Country,gii$Country)
common_by(by = Country, hd, gii)
common_by( by = hd$Country, hd, gii)
common <- filter(hd, hd$Country == gii$Country)
join_by <- c("common")
join_by
hd_gii <- inner_join(hd, gii, by = join_by, suffix = c(".hd", ".gii"))
join_by <- c("Country")
hd_gii <- inner_join(hd, gii, by = join_by, suffix = c(".hd", ".gii"))
hd_gii
options(max.print=1000000)
hd_gii
hd_gii <- inner_join(hd, gii, by = filter(hd, hd$Country == gii$Country), suffix = c(".hd", ".gii"))
hd_gii <- inner_join(hd, gii, by = join_by, suffix = c(".hd", ".gii"))
human <- inner_join(hd, gii, by = join_by, suffix = c(".hd", ".gii"))
write.csv2(human, file = "F:/IODS-project/data/human.csv") # separator is a semi-colon
write.csv(human, file = "F:/IODS-project/data/human1.csv") # separator is a comma
human2 <- inner_join(hd, gii, by = Country, suffix = c(".hd", ".gii"))
hd$Country
gii$Country
gii$Country == hd$Country
human2 <- inner_join(hd, gii, by = hd$Country, suffix = c(".hd", ".gii"))
Country <- c(hd$Country)
join_by <- c("Country")
human2 <- inner_join(hd, gii, by = Country, suffix = c(".hd", ".gii"))
Country <- c(gii$Country)
join_by <- c("Country")
human2 <- inner_join(hd, gii, by = Country, suffix = c(".hd", ".gii"))
Country <- c("gii$Country", "hd$Country")
join_by <- c("Country")
human2 <- inner_join(hd, gii, by = join_by, suffix = c(".hd", ".gii"))
write.csv2(human, file = "F:/IODS-project/data/human2.csv") # separator is a semi-colon
Country <- c(gii$Country, hd$Country)
join_by <- c("Country")
human2 <- inner_join(hd, gii, by = join_by, suffix = c(".hd", ".gii"))
write.csv2(human, file = "F:/IODS-project/data/human2.csv") # separator is a semi-colon
write.csv2(human, file = "F:/IODS-project/data/human3.csv") # separator is a semi-colon
Country <- c(gii$Country)
join_by <- c("Country")
human2 <- inner_join(hd, gii, by = join_by, suffix = c(".hd", ".gii"))
write.csv2(human, file = "F:/IODS-project/data/human4.csv") # separator is a semi-colon
human <- inner_join(hd, gii, by = join_by, suffix = c(".hd", ".gii"))
write.csv(human, file = "F:/IODS-project/data/human1.csv") # separator is a comma
write.csv2(human, file = "F:/IODS-project/data/human.csv") # separator is a semi-colon
dim(human)
setwd("F:/IODS-project")
setwd("F:/IODS-project")
